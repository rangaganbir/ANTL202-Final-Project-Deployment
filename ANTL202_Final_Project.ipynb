{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PHASE 1: LOAD DATA (Manual Upload Method)\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "filename = 'loan_dataset_20000.csv'\n",
        "\n",
        "# Check if you dragged the file over correctly\n",
        "if os.path.exists(filename):\n",
        "    print(f\"Success! Found {filename}...\")\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    print(\"\\n--- COLUMN NAMES ---\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    print(\"\\n--- DATA PREVIEW ---\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(f\"ERROR: Could not find '{filename}'.\")\n",
        "    print(\"Please open the Folder icon (left sidebar) and drag-and-drop your CSV file there first.\")"
      ],
      "metadata": {
        "id": "jA3FFiU28dY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1d8d38-2b0f-486c-aef9-2386df51f879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Found loan_dataset_20000.csv...\n",
            "\n",
            "--- COLUMN NAMES ---\n",
            "['age', 'gender', 'marital_status', 'education_level', 'annual_income', 'monthly_income', 'employment_status', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'loan_purpose', 'interest_rate', 'loan_term', 'installment', 'grade_subgrade', 'num_of_open_accounts', 'total_credit_limit', 'current_balance', 'delinquency_history', 'public_records', 'num_of_delinquencies', 'loan_paid_back']\n",
            "\n",
            "--- DATA PREVIEW ---\n",
            "   age  gender marital_status education_level  annual_income  monthly_income  \\\n",
            "0   59    Male        Married        Master's       24240.19         2020.02   \n",
            "1   72  Female        Married      Bachelor's       20172.98         1681.08   \n",
            "2   49  Female         Single     High School       26181.80         2181.82   \n",
            "3   35  Female         Single     High School       11873.84          989.49   \n",
            "4   63   Other         Single           Other       25326.44         2110.54   \n",
            "\n",
            "  employment_status  debt_to_income_ratio  credit_score  loan_amount  ...  \\\n",
            "0          Employed                 0.074           743     17173.72  ...   \n",
            "1          Employed                 0.219           531     22663.89  ...   \n",
            "2          Employed                 0.234           779      3631.36  ...   \n",
            "3          Employed                 0.264           809     14939.23  ...   \n",
            "4          Employed                 0.260           663     16551.71  ...   \n",
            "\n",
            "  loan_term  installment  grade_subgrade  num_of_open_accounts  \\\n",
            "0        36       581.88              B5                     7   \n",
            "1        60       573.17              F1                     5   \n",
            "2        60        76.32              B4                     2   \n",
            "3        36       468.07              A5                     7   \n",
            "4        60       395.50              D5                     1   \n",
            "\n",
            "  total_credit_limit  current_balance  delinquency_history  public_records  \\\n",
            "0           40833.47         24302.07                    1               0   \n",
            "1           27968.01         10803.01                    1               0   \n",
            "2           15502.25          4505.44                    0               0   \n",
            "3           18157.79          5525.63                    4               0   \n",
            "4           17467.56          3593.91                    2               0   \n",
            "\n",
            "   num_of_delinquencies  loan_paid_back  \n",
            "0                     1               1  \n",
            "1                     3               1  \n",
            "2                     0               1  \n",
            "3                     5               1  \n",
            "4                     2               1  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PHASE 2: DATA PREPROCESSING\n",
        "# ==========================================\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# 1. Loads the Data\n",
        "# df = pd.read_csv('loan_dataset_20000.csv')\n",
        "\n",
        "# Task A: Classification Target (e.g., 'loan_status', 'default')\n",
        "target_classification = 'loan_paid_back'\n",
        "\n",
        "# Task B: Regression Target (e.g., 'loan_amount', 'int_rate')\n",
        "target_regression = 'loan_amount'\n",
        "\n",
        "# Numeric Features (e.g., 'annual_inc', 'dti', 'open_acc')\n",
        "# Do NOT include the target columns here\n",
        "num_features = ['age', 'annual_income', 'monthly_income', 'debt_to_income_ratio', 'credit_score', 'interest_rate', 'loan_term', 'installment', 'num_of_open_accounts', 'total_credit_limit', 'current_balance', 'delinquency_history', 'public_records', 'num_of_delinquencies']\n",
        "\n",
        "# Categorical Features (e.g., 'grade', 'home_ownership')\n",
        "cat_features = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 2. Define Preprocessing Pipelines\n",
        "# Numeric Pipeline: Fills missing values with median, then scales the data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical Pipeline: Fills missing values with most frequent, then One-Hot Encodes\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combines the into a single Preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_features),\n",
        "        ('cat', categorical_transformer, cat_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "\n",
        "# 3. Data Splitting for Classification Task\n",
        "print(\"--- Splitting Data for Classification ---\")\n",
        "# Drop both targets from features to avoid data leakage\n",
        "X_class = df.drop(columns=[target_classification, target_regression])\n",
        "y_class = df[target_classification]\n",
        "\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
        "    X_class, y_class, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Classification Train Shape: {X_train_c.shape}\")\n",
        "print(f\"Classification Test Shape:  {X_test_c.shape}\")\n",
        "\n",
        "\n",
        "# 4. Data Splitting for Regression Task\n",
        "print(\"\\n--- Splitting Data for Regression ---\")\n",
        "# Drop both targets from features\n",
        "X_reg = df.drop(columns=[target_classification, target_regression])\n",
        "y_reg = df[target_regression]\n",
        "\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Regression Train Shape: {X_train_r.shape}\")\n",
        "print(f\"Regression Test Shape:  {X_test_r.shape}\")\n",
        "\n",
        "print(\"\\nPhase 2 Complete. Data is cleaned, scaled, and split.\")\n"
      ],
      "metadata": {
        "id": "sByJaHHfvpkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b72f47a-22ee-4745-cabb-39ccb26d8d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Splitting Data for Classification ---\n",
            "Classification Train Shape: (16000, 20)\n",
            "Classification Test Shape:  (4000, 20)\n",
            "\n",
            "--- Splitting Data for Regression ---\n",
            "Regression Train Shape: (16000, 20)\n",
            "Regression Test Shape:  (4000, 20)\n",
            "\n",
            "Phase 2 Complete. Data is cleaned, scaled, and split.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PHASE 3: CLASSICAL ML MODELS\n",
        "# ==========================================\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# --- PART A: CLASSIFICATION MODELS (Predicting Risk) ---\n",
        "print(\"=== PHASE 3A: CLASSIFICATION RESULTS ===\")\n",
        "\n",
        "# 1. Defines the pipeline with Logistic Regression\n",
        "clf_pipeline_log = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42, max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train and Predict\n",
        "clf_pipeline_log.fit(X_train_c, y_train_c)\n",
        "y_pred_log = clf_pipeline_log.predict(X_test_c)\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "print(\"\\n--- Model 1: Logistic Regression ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_c, y_pred_log):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test_c, y_pred_log, average='weighted'):.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_c, y_pred_log))\n",
        "\n",
        "\n",
        "# 2. Define Pipeline with Random Forest\n",
        "clf_pipeline_rf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Trains and Predicts\n",
        "clf_pipeline_rf.fit(X_train_c, y_train_c)\n",
        "y_pred_rf = clf_pipeline_rf.predict(X_test_c)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "print(\"\\n--- Model 2: Random Forest Classifier ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_c, y_pred_rf):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test_c, y_pred_rf, average='weighted'):.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_c, y_pred_rf))\n",
        "\n",
        "\n",
        "# --- PART B: REGRESSION MODELS (Predicting Financial Value) ---\n",
        "print(\"\\n=== PHASE 3B: REGRESSION RESULTS ===\")\n",
        "\n",
        "# 3. Defines the pipeline with Ridge Regression (Linear Model)\n",
        "reg_pipeline_ridge = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge(random_state=42))\n",
        "])\n",
        "\n",
        "# Trains and Predicts\n",
        "reg_pipeline_ridge.fit(X_train_r, y_train_r)\n",
        "y_pred_ridge = reg_pipeline_ridge.predict(X_test_r)\n",
        "\n",
        "# Evaluate Ridge Regression\n",
        "print(\"\\n--- Model 3: Ridge Regression ---\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test_r, y_pred_ridge):.2f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test_r, y_pred_ridge)):.2f}\")\n",
        "print(f\"R² Score: {r2_score(y_test_r, y_pred_ridge):.4f}\")\n",
        "\n",
        "\n",
        "# 4. Define Pipeline with Gradient Boosting\n",
        "reg_pipeline_gb = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Trains and Predicts\n",
        "reg_pipeline_gb.fit(X_train_r, y_train_r)\n",
        "y_pred_gb = reg_pipeline_gb.predict(X_test_r)\n",
        "\n",
        "# Evaluate Gradient Boosting\n",
        "print(\"\\n--- Model 4: Gradient Boosting Regressor ---\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test_r, y_pred_gb):.2f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test_r, y_pred_gb)):.2f}\")\n",
        "print(f\"R² Score: {r2_score(y_test_r, y_pred_gb):.4f}\")"
      ],
      "metadata": {
        "id": "GQYprs74vlMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a2acd0-9c80-43af-f780-3e6617c43dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 3A: CLASSIFICATION RESULTS ===\n",
            "\n",
            "--- Model 1: Logistic Regression ---\n",
            "Accuracy: 0.8808\n",
            "F1 Score: 0.8727\n",
            "Confusion Matrix:\n",
            " [[ 460  358]\n",
            " [ 119 3063]]\n",
            "\n",
            "--- Model 2: Random Forest Classifier ---\n",
            "Accuracy: 0.8935\n",
            "F1 Score: 0.8817\n",
            "Confusion Matrix:\n",
            " [[ 429  389]\n",
            " [  37 3145]]\n",
            "\n",
            "=== PHASE 3B: REGRESSION RESULTS ===\n",
            "\n",
            "--- Model 3: Ridge Regression ---\n",
            "MAE: 985.40\n",
            "RMSE: 1477.24\n",
            "R² Score: 0.9713\n",
            "\n",
            "--- Model 4: Gradient Boosting Regressor ---\n",
            "MAE: 186.57\n",
            "RMSE: 260.07\n",
            "R² Score: 0.9991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# PHASE 4: CLASSIFICATION - Model B: Tuned Random Forest Classifier\n",
        "#\n",
        "# =========================================================================\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "import joblib\n",
        "\n",
        "print(\"\\n--- Model B: Random Forest Classifier with Hyperparameter Tuning ---\")\n",
        "\n",
        "# 1. Define the Classification Pipeline (using the existing 'preprocessor' object)\n",
        "clf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# 2. Defines the parameter search space for the classifier\n",
        "param_grid_c = {\n",
        "    'classifier__n_estimators': [50, 100, 150],\n",
        "    'classifier__max_depth': [5, 10, None],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# 3. Performs the Grid Search\n",
        "grid_search_c = GridSearchCV(clf_pipeline, param_grid_c, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
        "grid_search_c.fit(X_train_c, y_train_c)\n",
        "\n",
        "print(f\"Best Parameters: {grid_search_c.best_params_}\")\n",
        "\n",
        "# 4. Evaluates which is the Best Model and Calculate the needed metrics\n",
        "best_rf_model = grid_search_c.best_estimator_\n",
        "\n",
        "# Get predictions and probabilities\n",
        "y_pred_tuned = best_rf_model.predict(X_test_c)\n",
        "\n",
        "y_proba_tuned = best_rf_model.predict_proba(X_test_c)[:, 1]\n",
        "\n",
        "# Calculate all required Classical ML metrics\n",
        "accuracy_tuned = accuracy_score(y_test_c, y_pred_tuned)\n",
        "f1_tuned = f1_score(y_test_c, y_pred_tuned, average='weighted', zero_division=0)\n",
        "precision_tuned = precision_score(y_test_c, y_pred_tuned, average='weighted', zero_division=0)\n",
        "recall_tuned = recall_score(y_test_c, y_pred_tuned, average='weighted', zero_division=0)\n",
        "# AUC-ROC for binary classification\n",
        "auc_roc_tuned = roc_auc_score(y_test_c, y_proba_tuned)\n",
        "\n",
        "print(\"\\n--- Tuned Random Forest Metrics (Full Set) ---\")\n",
        "print(f\"Tuned Accuracy: {accuracy_tuned:.4f}\")\n",
        "print(f\"Tuned F1-Score: {f1_tuned:.4f}\")\n",
        "print(f\"Tuned Precision: {precision_tuned:.4f}\")\n",
        "print(f\"Tuned Recall: {recall_tuned:.4f}\")\n",
        "print(f\"Tuned AUC-ROC: {auc_roc_tuned:.4f}\")\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "# Preparation for Phase 5\n",
        "# =========================================================================\n",
        "joblib.dump(best_rf_model, 'best_loan_classifier_pipeline.joblib')\n",
        "print(\"\\n[SUCCESS] Saved best model pipeline as 'best_loan_classifier_pipeline.joblib' for Phase 6 Deployment.\")\n"
      ],
      "metadata": {
        "id": "yUAkmUslwCz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ddd3a0-3f4b-4a5a-d585-c8c29f742be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model B: Random Forest Classifier with Hyperparameter Tuning ---\n",
            "Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
            "\n",
            "--- Tuned Random Forest Metrics (Full Set) ---\n",
            "Tuned Accuracy: 0.8935\n",
            "Tuned F1-Score: 0.8817\n",
            "Tuned Precision: 0.8962\n",
            "Tuned Recall: 0.8935\n",
            "Tuned AUC-ROC: 0.8759\n",
            "\n",
            "[SUCCESS] Saved best model pipeline as 'best_loan_classifier_pipeline.joblib' for Phase 6 Deployment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# PHASE 5: DEEP LEARNING MODEL (Classification Task)\n",
        "# =========================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n--- Phase 5: Deep Learning Model (Multi-Layer Perceptron) ---\")\n",
        "\n",
        "# --- 0. Setup: Re-calculate Classical Metrics for Comparison ---\n",
        "# If you didn't run Phase 4, replace 'grid_search_c' with 'clf_pipeline_rf' (from Phase 3).\n",
        "try:\n",
        "    best_rf_model = grid_search_c.best_estimator_\n",
        "    print(\"Using Tuned Random Forest from Phase 4 for comparison.\")\n",
        "except NameError:\n",
        "    # Fallback if Phase 4 wasn't run\n",
        "    best_rf_model = clf_pipeline_rf\n",
        "    best_rf_model.fit(X_train_c, y_train_c)\n",
        "    print(\"Using Standard Random Forest from Phase 3 for comparison.\")\n",
        "\n",
        "# Generate predictions for the Classical Model\n",
        "y_pred_tuned = best_rf_model.predict(X_test_c)\n",
        "y_prob_tuned = best_rf_model.predict_proba(X_test_c)[:, 1]\n",
        "\n",
        "# Save metrics to variables\n",
        "accuracy_tuned = accuracy_score(y_test_c, y_pred_tuned)\n",
        "f1_tuned = f1_score(y_test_c, y_pred_tuned, average='weighted')\n",
        "precision_tuned = precision_score(y_test_c, y_pred_tuned, average='weighted', zero_division=0)\n",
        "recall_tuned = recall_score(y_test_c, y_pred_tuned, average='weighted')\n",
        "auc_roc_tuned = roc_auc_score(y_test_c, y_prob_tuned)\n",
        "\n",
        "\n",
        "# --- 1. Preprocess and Transform Data for Keras ---\n",
        "# We fit the preprocessor explicitly to ensure it's ready\n",
        "preprocessor.fit(X_train_c, y_train_c)\n",
        "\n",
        "X_train_processed = preprocessor.transform(X_train_c)\n",
        "X_test_processed = preprocessor.transform(X_test_c)\n",
        "\n",
        "# Keras requires integer labels (0/1).\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_c)\n",
        "y_test_encoded = label_encoder.transform(y_test_c)\n",
        "\n",
        "input_dim = X_train_processed.shape[1] # Number of features\n",
        "\n",
        "# --- 2. Define the Keras Model (MLP Architecture) ---\n",
        "dl_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "    Dropout(0.3), # Regularization to prevent overfitting\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# --- 3. Compile the Model ---\n",
        "dl_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# --- 4. Train the Model ---\n",
        "print(\"\\nTraining Deep Learning Model...\")\n",
        "history = dl_model.fit(\n",
        "    X_train_processed,\n",
        "    y_train_encoded,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Deep Learning Model Training Complete.\")\n",
        "\n",
        "# --- 5. Evaluate the Model ---\n",
        "y_pred_probs_dl = dl_model.predict(X_test_processed, verbose=0)\n",
        "y_pred_dl = (y_pred_probs_dl > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate DL Metrics\n",
        "accuracy_dl = accuracy_score(y_test_encoded, y_pred_dl)\n",
        "f1_dl = f1_score(y_test_encoded, y_pred_dl, average='weighted', zero_division=0)\n",
        "precision_dl = precision_score(y_test_encoded, y_pred_dl, average='weighted', zero_division=0)\n",
        "recall_dl = recall_score(y_test_encoded, y_pred_dl, average='weighted', zero_division=0)\n",
        "auc_roc_dl = roc_auc_score(y_test_encoded, y_pred_probs_dl)\n",
        "\n",
        "# --- 6. Final Comparison ---\n",
        "print(\"\\n--- Performance Comparison (Deep Learning vs. Classical ML) ---\")\n",
        "comparison_data = {\n",
        "    'Metric': ['Accuracy', 'F1-Score', 'Precision', 'Recall', 'AUC-ROC'],\n",
        "    'Random Forest': [f\"{accuracy_tuned:.4f}\", f\"{f1_tuned:.4f}\", f\"{precision_tuned:.4f}\", f\"{recall_tuned:.4f}\", f\"{auc_roc_tuned:.4f}\"],\n",
        "    'Deep Learning': [f\"{accuracy_dl:.4f}\", f\"{f1_dl:.4f}\", f\"{precision_dl:.4f}\", f\"{recall_dl:.4f}\", f\"{auc_roc_dl:.4f}\"]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df.to_markdown(index=False))\n",
        "\n",
        "print(\"\\n--- Interpretability Discussion ---\")\n",
        "print(\"Classical models (Random Forest) offer clear feature importance ('white box').\")\n",
        "print(\"Deep Learning models (MLP) are 'black box' but may capture complex non-linear patterns.\")"
      ],
      "metadata": {
        "id": "jMBI3aZcwDfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2cbf24-8896-4e95-a81d-63d8efa83107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 5: Deep Learning Model (Multi-Layer Perceptron) ---\n",
            "Using Tuned Random Forest from Phase 4 for comparison.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Deep Learning Model...\n",
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7533 - loss: 0.5044 - val_accuracy: 0.8925 - val_loss: 0.2871\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.3275 - val_accuracy: 0.9000 - val_loss: 0.2686\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8919 - loss: 0.2971 - val_accuracy: 0.9056 - val_loss: 0.2612\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8972 - loss: 0.2842 - val_accuracy: 0.9050 - val_loss: 0.2569\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8990 - loss: 0.2675 - val_accuracy: 0.9050 - val_loss: 0.2611\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8994 - loss: 0.2735 - val_accuracy: 0.9038 - val_loss: 0.2567\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.2637 - val_accuracy: 0.9031 - val_loss: 0.2564\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2567 - val_accuracy: 0.9013 - val_loss: 0.2579\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.2610 - val_accuracy: 0.9038 - val_loss: 0.2597\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9004 - loss: 0.2587 - val_accuracy: 0.9050 - val_loss: 0.2558\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9043 - loss: 0.2537 - val_accuracy: 0.9013 - val_loss: 0.2555\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9065 - loss: 0.2491 - val_accuracy: 0.9050 - val_loss: 0.2535\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9028 - loss: 0.2582 - val_accuracy: 0.9050 - val_loss: 0.2561\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9038 - loss: 0.2529 - val_accuracy: 0.9019 - val_loss: 0.2573\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2452 - val_accuracy: 0.9044 - val_loss: 0.2547\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2519 - val_accuracy: 0.9031 - val_loss: 0.2546\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2475 - val_accuracy: 0.9044 - val_loss: 0.2569\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2437 - val_accuracy: 0.9044 - val_loss: 0.2535\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2448 - val_accuracy: 0.9019 - val_loss: 0.2594\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2403 - val_accuracy: 0.9056 - val_loss: 0.2579\n",
            "Deep Learning Model Training Complete.\n",
            "\n",
            "--- Performance Comparison (Deep Learning vs. Classical ML) ---\n",
            "| Metric    |   Random Forest |   Deep Learning |\n",
            "|:----------|----------------:|----------------:|\n",
            "| Accuracy  |          0.8935 |          0.8982 |\n",
            "| F1-Score  |          0.8817 |          0.8874 |\n",
            "| Precision |          0.8962 |          0.9016 |\n",
            "| Recall    |          0.8935 |          0.8982 |\n",
            "| AUC-ROC   |          0.8759 |          0.8881 |\n",
            "\n",
            "--- Interpretability Discussion ---\n",
            "Classical models (Random Forest) offer clear feature importance ('white box').\n",
            "Deep Learning models (MLP) are 'black box' but may capture complex non-linear patterns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# 7. MODEL SAVING (Deployment Prep)\n",
        "# =========================================================================\n",
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\n=== SAVING AND DOWNLOADING MODELS ===\")\n",
        "\n",
        "# 1. Saves the Classification Model (Random Forest)\n",
        "# Using the best_estimator_ from the grid search in Phase 4\n",
        "joblib.dump(grid_search_c.best_estimator_, 'classification_model.pkl')\n",
        "print(\"Saved: classification_model.pkl\")\n",
        "\n",
        "# 2. Saves the Regression Model (Gradient Boosting)\n",
        "# Using the best performing regression model from Phase 3\n",
        "joblib.dump(reg_pipeline_gb, 'regression_model.pkl')\n",
        "print(\"Saved: regression_model.pkl\")\n",
        "\n",
        "# 3. Saves the Deep Learning Model (Keras)\n",
        "dl_model.save('deep_learning_model.h5')\n",
        "print(\"Saved: deep_learning_model.h5\")\n",
        "\n",
        "# 4. Initiate the model downloads\n",
        "try:\n",
        "    files.download('classification_model.pkl')\n",
        "    files.download('regression_model.pkl')\n",
        "    files.download('deep_learning_model.h5')\n",
        "    print(\"Downloads started! Check your browser's download bar.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not automatically download. Please check the 'Files' sidebar on the left. Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "cZlrsjBQ7nb5",
        "outputId": "e5f2f685-516d-4bea-a56a-98b77f35bd27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SAVING AND DOWNLOADING MODELS ===\n",
            "Saved: classification_model.pkl\n",
            "Saved: regression_model.pkl\n",
            "Saved: deep_learning_model.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dd0fcd94-eafd-4750-aecc-f4c347cf24b0\", \"classification_model.pkl\", 28892459)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2a6e8b2e-c826-4bd4-8ed5-933eaeaf60ae\", \"regression_model.pkl\", 149069)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af8af10c-61db-4bdb-9be4-26c4d7575acb\", \"deep_learning_model.h5\", 112128)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloads started! Check your browser's download bar.\n"
          ]
        }
      ]
    }
  ]
}